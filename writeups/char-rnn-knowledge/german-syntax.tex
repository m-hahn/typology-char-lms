\subsubsection{German}%  We consider 4 constructions:
% \begin{inparaenum}[i)]
% \item article-noun gender agreement, possibly with material in the middle,
% \item determiner-noun case concord, again with material in the middle,
% \item preposition case sub-categorization, with material in the middle.
% \end{inparaenum}


\paragraph{Gender agreement}
Each German noun belongs to one of three genders (masculine, feminine, neuter), which are morphologically marked on the article. As the article and the noun can be separated by adjectives and adverbs, we can probe knowledge of nouns' lexical gender together with long-distance agreement.
We create stimuli of the form
\exg. \{\underline{der},\ die,\ das\} sehr rote Baum \\
the very red tree \\
%    article adverb adjective noun\\
%    `the very red tree'

%\begin{enumerate}[label={(\arabic*)}]
%	\item \begin{tabular}[t]{lllllll}
%	\{\underline{der}, die, das\}& sehr& rote& Baum \\
%	article & adverb & adjective & noun \\
%	the & very & red & tree
%\end{tabular}
%\end{enumerate}
where the correct nominative singular article (\emph{der}, in this case) matches the gender of the noun.
We then run the CNLM on the three versions of this phrase (removing whitespace) and record the probabilities it assigns to them. If the model assigns the highest probability to the version with the right article, we count it as a hit for the model. To avoid phrase segmentation ambiguities, we present phrases preceded and followed by a full stop.

%  \cite{de2006generating,mcdonald2013universal}
We select all nominative singular nouns from the German Universal Dependencies treebank. %, and all adjectives from the training set.
We construct four conditions varying the number of adverbs and adjectives between the article and the noun.
We first consider stimuli where no material intervenes.\footnote{Due to syncretism in the article paradigm, there is sometimes ambiguity in the choice of the correct article if the noun's morphology does not uniquely indicate that it is a nominative singular from. As this equally affects all feminine nouns, we did not remove such cases. Importantly, this issue is solved as soon as an adjective intervenes, as its form disambiguates case.}
In the second condition, an adjective with the correct (nominative singular) case ending, randomly selected from the training corpus, is added.
Crucially, the ending of the adjective does not reveal the gender of the noun.
In the third and fourth conditions, one (\emph{sehr}) or two adverbs (\emph{sehr extrem}) intervene between the article and the adjective.
These do not cue gender either.
In each condition, we obtained 2290 (m.), 2261 (f.), and 1111 (n.) stimuli.

Besides the CNLMs and the WordNLM, we constructed an n-gram baseline that chooses the article that occurs most frequently before the phrase in the training data, making a random choice in case of ties (e.g., if no article was observed). Here and below, when running the word-level model, we excluded nouns that were out of its vocabulary, reducing in a slightly easier test for this rival model. However, running the CNLMs on this reduced set only led to slight improvements, that we do not report here. 

Results are presented in the left part of Figure~\ref{fig:german-syntax}. The WordNLM  performs best, followed by the LSTM CNLM.
While the n-gram baseline performs similarly to the CNLM when there is no intervening material, accuracy drops to the random baseline (0.33) in the presence of an adjective.
%This can partly be attributed to our choice to choose the adjective randomly from the vocabulary.
Note that this problem would not be mitigated by interpolation with or backoff to lower-order n-grams, as the relevant gender information is present only on the first and last word of each stimulus. The contrast shows that, while direct association between articles and nouns can be learnt from simple corpus statistics, the CNLM has some capability to preserve the relevant information across more than a dozen timesteps. The RNN CNLM is much worse than the LSTM counterpart and even the n-gram model for the adjacent context, and its accuracy drops to random as more material intervenes. Note that, at the character level, even ``adjacent'' agreement requires carrying information through multiple steps (for example, in this specific case, the agreement violation would not emerge until enough characters of the noun have been processed to disambiguate its gender with respect to other forms beginning with the same prefixes). This might explain the lower performance of the RNN with respect to the LSTM.

% The exclusion of OOVs and thus limiting experiments on word-level models to frequent words might create an unfair advantage; running the CNLM only on those stimuli given to the word-level model results in slightly better accuracies but the same pattern of results.

\begin{figure*}
% \includegraphics[width=0.24\textwidth]{figures/german-gender-m.pdf}
% \includegraphics[width=0.24\textwidth]{figures/german-gender-f.pdf}
% \includegraphics[width=0.24\textwidth]{figures/german-gender-n.pdf}
	\begin{tabular}{ccc}
Gender & Case & Subcategorization \\
\includegraphics[width=0.33\textwidth]{figures/german-gender-total.pdf} 
		&
		\includegraphics[width=0.33\textwidth]{figures/german-case-total.pdf}
		&
\includegraphics[width=0.33\textwidth]{figures/german-prep-with-control.pdf}
	\end{tabular}
\centering\includegraphics[width=0.5\textwidth]{figures/german-legend.pdf}
\caption{Accuracy on the German syntax tasks, as a function of the number of intervening elements.}\label{fig:german-syntax}
\end{figure*}


\paragraph{Case agreement}
To test the model's knowledge of case agreement between articles and
nouns, we selected the two determiners \emph{dem} and \emph{des},
which unambiguously indicate dative and genitive case, respectively
(for masculine and neuter nouns): %\textbf{Give one example.}
\ex.\ag. \{\underline{dem},des\} sehr roten Baum \\
the very reed tree\ (dative)\\
\bg. \{dem,\underline{des}\} sehr roten Baums \\
the very red tree\ (genitive) \\
%\begin{enumerate}[label={(\arabic*)}]
%	\item \begin{tabular}[t]{lllllll}
%	\{\underline{dem}, des\}& sehr& roten& Baum \\
%	article & adverb & adjective & noun \\
%	the & very & red & tree
%\end{tabular}
%\item \begin{tabular}[t]{lllllll}
%	\{dem, \underline{des}\}& sehr& roten& Baums \\
%	article & adverb & adjective & noun \\
%	the & very & red & tree
%\end{tabular}
%
%\end{enumerate}


We selected all noun lemmas of the
appropriate genders from the Universal Dependencies, and extracted
morphological paradigms from Wiktionary to obtain case-marked forms,
retaining only nouns that unambiguously mark the two cases.  We created
four conditions, varying the amount of intervening material, as in the
gender agreement experiment.
In each condition, there were 4509 stimuli.

Results are shown in the central part of Figure~\ref{fig:german-syntax}.  Again, the WordNLM has
the strongest overall performance, but the CNLM is competitive as more
elements intervene. Accuracy stays well above 80\% even as three
words intervene.  The n-gram model performs well if there is no
intervening material, and at chance otherwise.  Accuracy of the RNN
CNLM remains above chance for one or two intervening elements, but
drops considerably.

% Considering the results for the dative and genitive separately, accuracy slightly increases in the dative case and decreases in the genitive case.
% This can be attributed to the higher baseline frequency of dative in German, suggesting that both word- and character-based networks are impacted by unigram frequencies as more words intervene.
% This effect is far more pronounced for the RNN CNLM, explaining its overall decrease to chance level.
% Again, restricting to words that are in the word-level vocabulary did not change the pattern of results.
%\begin{figure}
%% \includegraphics[width=0.23\textwidth]{figures/german-case-Dative.pdf}
%% \includegraphics[width=0.23\textwidth]{figures/german-case-Genitive.pdf} \\
%
%\centering\includegraphics[width=0.24\textwidth]{figures/german-case-total.pdf}
%
%\includegraphics[width=0.5\textwidth]{figures/german-legend.pdf}
%	\caption{\textbf{(Reduce to single figure, 2)} Accuracy on the case agreement task as a function of the number of intervening elements.}\label{fig:case}
%\end{figure}

\paragraph{Case subcategorization}
German verbs and prepositions lexically specify the case appropriate
to their objects (mostly dative or accusative).  We probe the CNLMs
knowledge of such generalizations using the preposition \textit{mit}
`with', which selects a dative object. To focus on knowledge of
subcategorization (as opposed to inflectional paradigms), we construct
objects whose head noun is a nominalized adjective, whose inflection
is very regular.  We take all adjectives that occur at least 100 times
in the training data, excluding those that end in -\emph{r}, as these
often reflected lemmatization problems.

We then select all sentences containing a \emph{mit} prepositional phrase in Universal Dependencies, subject to the constraints that (1) the object is not a pronoun (such objects often are relative or interrogative pronouns and cannot be replaced with a nominal object without sacrificing grammaticality), and (2) the object is a continuous phrase, i.e., it is not interrupted by words that do not belong to it. %\textbf{(please explain the latter more clearly)}.
We obtained 1629 such sentences.
For each sentence, we remove the prepositional phrase and replace it by a phrase of the form
\exg. mit der sehr \{rote,\ \underline{roten}\} \\
with the very red\ one \\

%\begin{enumerate}[label={(\arabic*)}]
%	\item \begin{tabular}[t]{lllllll}
%	mit & der & sehr& \{rote, \underline{roten}\} \\
%	prep & article  & adverb & adjective \\
%	with & the & very  & red one 
%\end{tabular}
%\end{enumerate}
where only the \emph{-en} version of the adjective is compatible with
the case requirement of the preposition. Note that this correct
version is longer than the wrong one. This ensures that the
probabilistic bias for shorter sequences works against the model.  We
construct three conditions by varying the presence and number of
adverbs (\emph{sehr} `very', \emph{sehr extrem} `very extremely',
\emph{sehr extrem unglaublich} `very extremely incredibly').  As a
control for baseline probabilities of the two versions of the
adjective, we also created control stimuli where all words up to the
preposition were removed, and computed accuracy on these stimuli.  If
accuracy is lower on these stimuli than on the full stimuli, we can
conclude that the baseline probabilities of the two adjective forms
cannot explain success on the task. For the n-gram count model, we
only counted the occurrences of the prepositional phrase, omitting the
sentence environment.

%\begin{figure}
%\includegraphics[width=0.48\textwidth]{figures/german-prep-with-control.pdf}
%
%\includegraphics[width=0.48\textwidth]{figures/german-legend.pdf}
%\caption{\textbf{(Reduce to single figure, 3)} Accuracy on the subcategorization task as a function of the number of intervening elements. The dashed lines indicate accuracies on the control stimuli that do not contain the preposition.}\label{fig:prep}
%\end{figure}
%
Results are shown in the right part of Figure~\ref{fig:german-syntax}. All models except the one
based on n-gram counts outperform the accuracy achieved on the control
stimuli that did not include the preposition, showing that their
performance cannot be attributed to baseline frequencies of the
adjective forms, and that they take the preposition into account when
choosing the adjective form.  Surprisingly, the LSTM CNLM slightly
outperforms the word language model, even though the CNLM is exposed
to a harder test set without OOV removal.  Neither model shows
accuracy decay as the number of adverbs increases.  As before, the
n-gram model drops to chance as adverbs intervene, while the RNN CNLM
starts with low accuracy that decays below chance.

%Results are shown in Table~\ref{tab:ital-agr-results}.
%The word LSTM shows the highest overall performance, closely followed by the LSTM CNLM.
%The RNN performs well on adjective gender, and considerably worse than the CNLM on the other tasks.
%For the CNLMs, the most challenging task was article-noun gender agreement.
%Discussion case-by-case, including how we control for n-gram frequency
%and length.
%Results table with a row for each pattern and a column for each model.

